{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = ['How may I help you?',\n",
    "             'Can I be of assistance?',\n",
    "             'May I help you with something?',\n",
    "             'May I assist you?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = dict()\n",
    "reverse = dict()\n",
    "i = 0\n",
    "for s in sentences:\n",
    "    s = s.replace('?',' <unk>')\n",
    "    for w in s.split():\n",
    "        if w.lower() not in words:\n",
    "            words[w.lower()] = i\n",
    "            reverse[i] = w.lower()\n",
    "            i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataGenerator():\n",
    "    def __init__(self, dset):\n",
    "        self.dset = dset\n",
    "        self.len = len(self.dset)\n",
    "        self.idx = 0\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        x = Variable(torch.LongTensor([[self.dset[self.idx]]]), requires_grad=False)\n",
    "        if self.idx == self.len - 1:\n",
    "            raise StopIteration\n",
    "        y = Variable(torch.LongTensor([self.dset[self.idx+1]]), requires_grad=False)\n",
    "        self.idx = self.idx + 1\n",
    "        return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BotBrain(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(len(words), 10)\n",
    "        self.rnn = nn.LSTM(10, 20, 2, dropout=0.5)\n",
    "        self.h = (Variable(torch.zeros(2, 1, 20)), Variable(torch.zeros(2, 1, 20)))\n",
    "        self.l_out = nn.Linear(20, len(words))\n",
    "        \n",
    "    def forward(self, cs):\n",
    "        inp = self.embedding(cs)\n",
    "        outp,h = self.rnn(inp, self.h)\n",
    "        out = F.log_softmax(self.l_out(outp), dim=-1).view(-1, len(words))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = BotBrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1.6654\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(m.parameters(), lr=0.01)\n",
    "for epoch in range(0,300):\n",
    "    gen = DataGenerator([words[word.lower()] for word in ' '.join(sentences).replace('?',' <unk>').split(' ')])\n",
    "    for x, y in gen:\n",
    "        m.zero_grad()\n",
    "        output = m(x)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next(word_):\n",
    "    word = word_.lower()\n",
    "    out = m(Variable(torch.LongTensor([words[word_]])))\n",
    "    return reverse[int(out.max(dim=1)[1].data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next_n(word_, n=3):\n",
    "    print(word_)\n",
    "    for i in range(0, n):\n",
    "        word_ = get_next(word_)\n",
    "        print(word_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_next_n('<unk>', n=12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
